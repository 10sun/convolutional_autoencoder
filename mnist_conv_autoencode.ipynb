{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, pickle, cPickle, sys, urllib, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import InputLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
    "from lasagne.nonlinearities import tanh\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda_convnet (faster)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import Conv2DLayer as Conv2DLayerSlow\n",
    "from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerSlow\n",
    "try:\n",
    "    from lasagne.layers.cuda_convnet import Conv2DCCLayer as Conv2DLayerFast\n",
    "    from lasagne.layers.cuda_convnet import MaxPool2DCCLayer as MaxPool2DLayerFast\n",
    "    print 'Using cuda_convnet (faster)'\n",
    "except ImportError:\n",
    "    from lasagne.layers import Conv2DLayer as Conv2DLayerFast\n",
    "    from lasagne.layers import MaxPool2DLayer as MaxPool2DLayerFast\n",
    "    print 'Using lasagne.layers (slower)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### when we load the batches to input to the neural network, we randomly / flip rotate the images, to artificially\n",
    "### increase the size of the training set\n",
    "\n",
    "class FlipBatchIterator(BatchIterator):\n",
    "\n",
    "    def transform(self, X1, X2):\n",
    "        X1b, X2b = super(FlipBatchIterator, self).transform(X1, X2)\n",
    "        X2b = X2b.reshape(X1b.shape)\n",
    "\n",
    "        bs = X1b.shape[0]\n",
    "        h_indices = np.random.choice(bs, bs / 2, replace=False) # horizontal flip\n",
    "        v_indices = np.random.choice(bs, bs / 2, replace=False) # vertical flip\n",
    "        \n",
    "        ###  uncomment these lines if you want to include rotations (images must be square)  ###\n",
    "        #r_indices = np.random.choice(bs, bs / 2, replace=False) # 90 degree rotation\n",
    "        for X in (X1b, X2b):\n",
    "            X[h_indices] = X[h_indices, :, :, ::-1]\n",
    "            X[v_indices] = X[v_indices, :, ::-1, :]\n",
    "            #X[r_indices] = np.swapaxes(X[r_indices, :, :, :], 2, 3)\n",
    "        shape = X2b.shape\n",
    "        X2b = X2b.reshape((shape[0], -1))\n",
    "\n",
    "        return X1b, X2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = 'mnist/mnist.pkl.gz'\n",
    "if not os.path.isfile(fname):\n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", fname)\n",
    "f = gzip.open(fname, 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "X, y = train_set\n",
    "X = np.rint(X * 256).astype(np.int).reshape((-1, 1, 28,28)) # convert to (0,255) int range (we'll do our own scaling)\n",
    "mu, sigma = np.mean(X.flatten()), np.std(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X.astype(np.float64)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# we need our target to be 1 dimensional\n",
    "X_out = X_train.reshape((X_train.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_num_filters = 32\n",
    "conv_filter_size = 7\n",
    "pool_size = 2\n",
    "deconv_filters = 32\n",
    "epochs = 20\n",
    "encode_size = 40\n",
    "layers = [\n",
    "    (InputLayer, {'shape': (None, X.shape[1], X.shape[2], X.shape[3])}), \n",
    "    (Conv2DLayerFast, {'num_filters': conv_num_filters, 'filter_size': conv_filter_size, 'nonlinearity': None}),\n",
    "    (MaxPool2DLayerFast, {'pool_size': pool_size}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}), # not sure if necessary?\n",
    "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
    "    (DenseLayer, {'num_units': deconv_filters * (28 + conv_filter_size - 1) ** 2 / 4}),\n",
    "    (ReshapeLayer, {'shape': (([0], deconv_filters, (28 + conv_filter_size - 1) / 2, (28 + conv_filter_size - 1) / 2 ))}),\n",
    "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
    "    (Conv2DLayerSlow, {'num_filters': 1, 'filter_size': conv_filter_size, 'nonlinearity': None}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae = NeuralNet(\n",
    "    layers=layers,\n",
    "    max_epochs=epochs,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.975,\n",
    "    \n",
    "    batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    regression=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 537257 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name          size\n",
      "---  ------------  --------\n",
      "  0  input0        1x28x28\n",
      "  1  conv2dcc1     32x22x22\n",
      "  2  maxpool2dcc2  32x11x11\n",
      "  3  reshape3      3872\n",
      "  4  encode        40\n",
      "  5  dense5        9248\n",
      "  6  reshape6      32x17x17\n",
      "  7  upscale2d7    32x34x34\n",
      "  8  conv2d8       1x28x28\n",
      "  9  reshape9      784\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  ------\n",
      "      1       \u001b[36m0.42793\u001b[0m       \u001b[32m0.21328\u001b[0m      2.00647  11.05s\n",
      "      2       \u001b[36m0.17378\u001b[0m       \u001b[32m0.14758\u001b[0m      1.17751  11.02s\n",
      "      3       \u001b[36m0.13602\u001b[0m       \u001b[32m0.12634\u001b[0m      1.07664  11.03s\n",
      "      4       \u001b[36m0.12152\u001b[0m       \u001b[32m0.11637\u001b[0m      1.04425  11.04s\n",
      "      5       \u001b[36m0.11364\u001b[0m       \u001b[32m0.11070\u001b[0m      1.02658  11.14s\n",
      "      6       \u001b[36m0.10870\u001b[0m       \u001b[32m0.10651\u001b[0m      1.02059  11.19s\n",
      "      7       \u001b[36m0.10528\u001b[0m       \u001b[32m0.10385\u001b[0m      1.01376  11.19s\n",
      "      8       \u001b[36m0.10233\u001b[0m       \u001b[32m0.10110\u001b[0m      1.01217  11.18s\n",
      "      9       \u001b[36m0.10007\u001b[0m       \u001b[32m0.09894\u001b[0m      1.01151  11.20s\n",
      "     10       \u001b[36m0.09825\u001b[0m       \u001b[32m0.09715\u001b[0m      1.01129  11.24s\n",
      "     11       \u001b[36m0.09671\u001b[0m       \u001b[32m0.09595\u001b[0m      1.00798  11.19s\n",
      "     12       \u001b[36m0.09519\u001b[0m       \u001b[32m0.09434\u001b[0m      1.00901  11.18s\n",
      "     13       \u001b[36m0.09381\u001b[0m       \u001b[32m0.09373\u001b[0m      1.00081  11.19s\n",
      "     14       \u001b[36m0.09337\u001b[0m       \u001b[32m0.09353\u001b[0m      0.99831  11.20s\n",
      "     15       \u001b[36m0.09168\u001b[0m       \u001b[32m0.09101\u001b[0m      1.00741  11.19s\n",
      "     16       \u001b[36m0.09042\u001b[0m       \u001b[32m0.09019\u001b[0m      1.00256  11.18s\n",
      "     17       \u001b[36m0.08971\u001b[0m       \u001b[32m0.08934\u001b[0m      1.00409  11.19s\n",
      "     18       \u001b[36m0.08914\u001b[0m       \u001b[32m0.08893\u001b[0m      1.00233  11.19s\n",
      "     19       \u001b[36m0.08804\u001b[0m       \u001b[32m0.08795\u001b[0m      1.00101  11.21s\n",
      "     20       \u001b[36m0.08735\u001b[0m       \u001b[32m0.08698\u001b[0m      1.00424  11.15s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ae.fit(X_train, X_out)\n",
    "print \n",
    "###  expect training / val error of about 0.087 with these parameters\n",
    "###  if your GPU not fast enough, reduce the number of filters in the conv/deconv step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "pickle.dump(ae, open('mnist/conv_ae.pkl','w'))\n",
    "#ae = pickle.load(open('mnist/conv_ae.pkl','r'))\n",
    "ae.save_params_to('mnist/conv_ae.np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = ae.predict(X_train).reshape(-1, 28, 28) * sigma + mu\n",
    "X_pred = np.rint(X_train_pred).astype(int)\n",
    "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
    "X_pred = X_pred.astype('uint8')\n",
    "print X_pred.shape , X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAABwCAAAAAAiICN+AAAFpUlEQVR4nO3cTaxdVRUH8N+9791+\nRqOIfBjUCGqAAQmNQMAOYFaTEr/FKANGBh0gY1IGJs4YyIBIwoCPATDACVASEj9CgChRI5ZGawpW\nrWAF27TWtrSP995lsPbO2ff0vnfvfRAf5/T8k5tz9z5nn33WXfeftfZaa5+edUAPwwl981isXTOX\nrutjoRiT+5bGzNV/H573A41OwKajt16Tlnzrp3bZN5eOyyqe5XEDwbc65/rp+npfq9EJ2HSsCwdL\nzvWKPkZ51RP2cOhsm1jeq867+vlWoxOw6Zhfj0kzZ3oqe1fnWHmu5NhA5YsOi2tX8m1br8FOwKbj\n/87BOl+WjTfGW9N1J4u+PjaqbOiClW3gsBjTanQCNh3r4ouWk9ft1xacTt9X4te80MziCteUa8fW\na7ATsOmYiYMbcAd24nncj0NrnDRPXHJos+DVO6l9ObbjMhzDz/GHCfdlNEbaeg12AjYdU3NwDvfi\nB8XA/+Ba/GPGSeeMxkFLv3FZrPmuxw/xtWLcr/AAnsV/V7l/aV9br8FOwKZjKg5+GbuwrTZwiL/i\nO/j9DJPmWMswfR/glPi1Pyr49118K/WdEetAeBkP4Qn822hctLODbUTrBZwYk7kT96h+iQX8RPzf\n7xR+4pPpePrs4WNR5h/mhI97Kj3MNbgNX0lzPi580M/hS/iM8IVfERzsiTUkwdUyxtN3DmiwE7Dp\nWJWDA/G/z7/C2/geHkvtg7gPF+F24atOQj0f3xO8ho/g2/h6ar+Jffhz+j6Hrwr/dzt+m55Jul/m\n9lLR13oNdgI2Hav6ohfiX0X7aREvuQTHhR18CpfiNdyAI1NM2FP5jxtS+4zwdR8VsRj4o+DZIWHr\ntgj+XYNf4m78TsW1HMsp0XoNdgI2HavawWxb8vrt5uJcD7/GfsHBz+IKvDjFpPV8RObORqP+7JWC\n70tpvr8XD3wZrsJenFCtLYdGY62t12AnYNOxKgffws9wy5hzh3DYaH3L903mYL1OtK8yxq/jN2Lt\nt1XYyM2CY4fxP5yXrt0qfNdBaue6msy/7O+2XoOdgE3HxJjMg4IT27AHz2E3XsU/RWzkvSDbr6V0\nv93poT6ENwQvj4hcxKX4ZhrXrx0Je1quM+vnW4lOwKZjIgd/gZfwcZUtyvgiPl+0H55x8mURjxmo\n/Mg9OCpq1A6KeGn2RXeo7N58epYTqT1u3xLngAY7AZuOqepFT6j+6xkD/Ej4ixnHp5y0l8bnWrMF\nfDg9zDERAy1jNpvS8YL0IWzjQRHLyYJkv7jMGbZeg52ATceaa7Y/iZtUvt/+9JkGOdZTxk4yl8oa\n7Q2qNeMnhD/8qXTuL2K9SrWXYtz+ptZrsBOw6VgzB2+ttY+mzzToOdt3XFDlCet9p/ANEZftCZu8\nX2V3l43yr8xBtl6DnYBNx5o5uLPW/umU4+oJybJ2tJ6zyLhC1MtlG/iKiJ++Zfwe/LLdeg12AjYd\na+LgxfiC6n9+HC/MML7ky0qxlPNVub4bcXVx7k+ChydFjmJBlWMs8/+cAxrsBGw61sTBXbX2HrPv\nnRiHTYJLSyI2s0XUwX1acI2wfQfFno0FYUfzWjJrq56DbDU6AZuOmTm4Q9SMZizixzOML/N3dZs1\nlz4n033nRT3MNpGPh7/hgNE4bY6D1vfz5vettRqdgE3HzBy8TlXbMsQjIoc4K8at/ZZEvdpGYeM2\n4WPCFmbsFxxcEnZy3vh3WnQ5+rag9QLOzMGX03EocvaPvIfJ6zw8kx5oIHzSo6J2Zp/wR/eKfVIv\npevH5SJynrCLybQFrRdwZg4eEO+x6OEuUbf9fiG/wynb2UWxH+MZsX/jgMmxn9Iedr5oG9B6AT9w\n73QqsVlo4Dyxj2pR8DDnBbO9rN8rC9XlB9uA1gu4rhychJJXGwUnTwufdaX3iY57h3er0QnYdLwL\njv9Gj9Ydb14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  show random inputs / outputs side by side\n",
    "\n",
    "def get_picture_array(X, index):\n",
    "    array = X[index].reshape(28,28)\n",
    "    array = np.clip(array, a_min = 0, a_max = 255)\n",
    "    return  array.repeat(4, axis = 0).repeat(4, axis = 1).astype(np.uint8())\n",
    "\n",
    "def get_random_images():\n",
    "    index = np.random.randint(5000)\n",
    "    print index\n",
    "    original_image = Image.fromarray(get_picture_array(X, index))\n",
    "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
    "    new_im = Image.new('L', new_size)\n",
    "    new_im.paste(original_image, (0,0))\n",
    "    rec_image = Image.fromarray(get_picture_array(X_pred, index))\n",
    "    new_im.paste(rec_image, (original_image.size[0],0))\n",
    "    new_im.save('data/test.png', format=\"PNG\")    \n",
    "    \n",
    "get_random_images()\n",
    "IPImage('data/test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import get_output\n",
    "## we find the encode layer from our ae, and use it to define an encoding function\n",
    "\n",
    "encode_layer_index = 4\n",
    "encode_layer = ae.get_all_layers()[encode_layer_index]\n",
    "\n",
    "def get_output_from_nn(last_layer, X):\n",
    "    indices = np.arange(128, X.shape[0], 128)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # not splitting into batches can cause a memory error\n",
    "    X_batches = np.split(X, indices)\n",
    "    out = []\n",
    "    for count, X_batch in enumerate(X_batches):\n",
    "        out.append(get_output(last_layer, inputs=X_batch).eval())\n",
    "        sys.stdout.flush()\n",
    "    return np.vstack(out)\n",
    "\n",
    "\n",
    "def encode_input(X):\n",
    "    return get_output_from_nn(encode_layer, X)\n",
    "\n",
    "X_encoded = encode_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAADUUlEQVR4nO2aS27UQBCGP489YUYJ\nhECQeAghkGAFV2CfQ3A59lwATsAFEAiQWCDEWwgUkoxnbBbVFZfb7ZlsbKOOf2lku90Pq2rq8Vd3\nApAAJQJ772MCFC3vFIm7rpujV8S/YLK5S4UpohsdtDTP9j9gJy1Me8l5EGnvC2ZtX9Fmb8uWSVZr\nxkCl4/hF+n/YodpSSdgn7iE2+dU961f7Nuff2769If4FGzpMzFV1MgcWiK09Ap4A14FnwHPgCLjg\n+ucbFoxfpMP60gRIEbtZeZ0miB+9CxwAD4F94DXwxusfwhgPO0MwHvo4BmbANmJnP137Y+A+osPl\nGSeLX6TD6lDjX0I9r8ndbw4cAp9d+zZw04wPBVedZ8xpOkPDl5bUZW5xBHxDYqNiH9FtjvhhjYc2\nJ7J5TfwiHUaHlpfbfFLbtqj0VgBXzQQzJJ9Jka8/ce0TJEb6/4X4Rdq/DieEOUSK6DGnrke1UxC/\n+t1dM9cnRWJjG1eMX6T967CgGcc0N1U+v0Ji3wLR1zvgN5LrqL3l7n5TzS5+kQ6fl6oe1DfmiE2p\nLz0EPgF/EY54B+H7J66vcgzfDkdu0RkyqNtOhtjfyvsa1WFq+oLUbDJEh23+c8xpOsWpHdr6Gog+\nCq9jjtjcLqI7gBuIPb5342eIj21D/CIdToeWA6iNpeaqvKFAuMSWe7cL7Lj7pWsP7WNo7S5+kQ7P\nLVZUHN/yRcUOlc5OJzDjNebpPL4fjV+kw9dpFGqDfh30EuI7FV+o17kXVDr3+eZoh52g5kv9r1Bu\noVyjcAOuufZfwAuEayiU1/vcYsxLO0MW4nH+85Rqj7cELrr2V8BL6rW30ruO+4edI7jVsG4/fkbd\nDv+YdqjnpBpT7R5//CIdvubt55AFwv2sXWn8mwOX3f0xUjdVpIQRv0j712GoHqZ5qXJCa5cfER96\nC3gA3DbvFjTPcPg2Hb9Ih89L7RkMq1+teX8AngJXgB/IXpQ/3vJMtWV77RXxL5i05Y96r78pkqdq\nrnoP8ZdvQ5NSrxWMOU2nSM5y7le5RUY9B1VMEX3ZPafQ2So4DyId9lxbSsUfEsI8b0JVd0uRfDSn\nioXQ5Ca60MgPO0HrOW+rj7a9wIzmGbhNiF+kvS/4D8cQ4E+MRoujAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
    "final_layer = ae.get_all_layers()[-1]\n",
    "new_layer = InputLayer(shape=(None, encode_layer.num_units))\n",
    "\n",
    "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
    "next_layer.input_layer = new_layer\n",
    "\n",
    "def decode_encoded_input(X):\n",
    "    return get_output_from_nn(final_layer, X)\n",
    "\n",
    "X_decoded = decode_encoded_input(X_encoded) * sigma + mu\n",
    "\n",
    "X_decoded = np.rint(X_decoded ).astype(int)\n",
    "X_decoded = np.clip(X_decoded, a_min = 0, a_max = 255)\n",
    "X_decoded  = X_decoded.astype('uint8')\n",
    "print X_decoded.shape\n",
    "\n",
    "### check it worked :\n",
    "\n",
    "pic_array = get_picture_array(X_decoded, np.random.randint(len(X_decoded)))\n",
    "image = Image.fromarray(pic_array)\n",
    "image.save('data/test.png', format=\"PNG\")  \n",
    "IPImage('data/test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
