{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, pickle, cPickle, sys, urllib, gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "from lasagne.nonlinearities import tanh\n",
    "from lasagne.layers import InputLayer, Conv2DLayer, MaxPool2DLayer, DenseLayer, Upscale2DLayer, ReshapeLayer\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### when we load the batches to input to the neural network, we randomly / flip rotate the images, to artificially\n",
    "### increase the size of the training set\n",
    "\n",
    "class FlipBatchIterator(BatchIterator):\n",
    "\n",
    "    def transform(self, X1, X2):\n",
    "        X1b, X2b = super(FlipBatchIterator, self).transform(X1, X2)\n",
    "        X2b = X2b.reshape(X1b.shape)\n",
    "\n",
    "        bs = X1b.shape[0]\n",
    "        h_indices = np.random.choice(bs, bs / 2, replace=False) # horizontal flip\n",
    "        v_indices = np.random.choice(bs, bs / 2, replace=False) # vertical flip\n",
    "        \n",
    "        ###  uncomment these lines if you want to include rotations (images must be square)  ###\n",
    "        #r_indices = np.random.choice(bs, bs / 2, replace=False) # 90 degree rotation\n",
    "        for X in (X1b, X2b):\n",
    "            X[h_indices] = X[h_indices, :, :, ::-1]\n",
    "            X[v_indices] = X[v_indices, :, ::-1, :]\n",
    "            #X[r_indices] = np.swapaxes(X[r_indices, :, :, :], 2, 3)\n",
    "        shape = X2b.shape\n",
    "        X2b = X2b.reshape((shape[0], -1))\n",
    "\n",
    "        return X1b, X2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = 'mnist/mnist.pkl.gz'\n",
    "if not os.path.isfile(fname):\n",
    "    testfile = urllib.URLopener()\n",
    "    testfile.retrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", fname)\n",
    "f = gzip.open(fname, 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "X, y = train_set\n",
    "X = np.rint(X * 256).astype(np.int).reshape((-1, 1, 28,28)) # convert to (0,255) int range (we'll do our own scaling)\n",
    "mu, sigma = np.mean(X.flatten()), np.std(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X.astype(np.float64)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# we need our target to be 1 dimensional\n",
    "X_out = X_train.reshape((X_train.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_num_filters = 32\n",
    "conv_filter_size = 7\n",
    "pool_size = 2\n",
    "deconv_filters = 32\n",
    "epochs = 20\n",
    "encode_size = 40\n",
    "layers = [\n",
    "    (InputLayer, {'shape': (None, X.shape[1], X.shape[2], X.shape[3])}), \n",
    "    (Conv2DLayer, {'num_filters': conv_num_filters, 'filter_size': conv_filter_size, 'nonlinearity': None}),\n",
    "    (MaxPool2DLayer, {'pool_size': pool_size}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}), # not sure if necessary?\n",
    "    (DenseLayer, {'name': 'encode', 'num_units': encode_size}),\n",
    "    (DenseLayer, {'num_units': deconv_filters * (28 + conv_filter_size - 1) ** 2 / 4}),\n",
    "    (ReshapeLayer, {'shape': (([0], deconv_filters, (28 + conv_filter_size - 1) / 2, (28 + conv_filter_size - 1) / 2 ))}),\n",
    "    (Upscale2DLayer, {'scale_factor': pool_size}),\n",
    "    (Conv2DLayer, {'num_filters': 1, 'filter_size': conv_filter_size, 'nonlinearity': None}),\n",
    "    (ReshapeLayer, {'shape': (([0], -1))}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae = NeuralNet(\n",
    "    layers=layers,\n",
    "    max_epochs=epochs,\n",
    "    \n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.01,\n",
    "    update_momentum=0.975,\n",
    "    \n",
    "    batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
    "    regression=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 537257 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name        size\n",
      "---  ----------  --------\n",
      "  0  input0      1x28x28\n",
      "  1  conv2d1     32x22x22\n",
      "  2  maxpool2d2  32x11x11\n",
      "  3  reshape3    3872\n",
      "  4  dense4      40\n",
      "  5  dense5      9248\n",
      "  6  reshape6    32x17x17\n",
      "  7  upscale2d7  32x34x34\n",
      "  8  conv2d8     1x28x28\n",
      "  9  reshape9    784\n",
      "\n",
      "  epoch    train loss    valid loss    train/val  dur\n",
      "-------  ------------  ------------  -----------  ------\n",
      "      1       \u001b[36m0.45560\u001b[0m       \u001b[32m0.21737\u001b[0m      2.09594  11.07s\n",
      "      2       \u001b[36m0.17652\u001b[0m       \u001b[32m0.14832\u001b[0m      1.19007  11.05s\n",
      "      3       \u001b[36m0.13819\u001b[0m       \u001b[32m0.12739\u001b[0m      1.08480  11.06s\n",
      "      4       \u001b[36m0.12286\u001b[0m       \u001b[32m0.11699\u001b[0m      1.05013  11.17s\n",
      "      5       \u001b[36m0.11463\u001b[0m       \u001b[32m0.11081\u001b[0m      1.03446  11.22s\n",
      "      6       \u001b[36m0.10913\u001b[0m       \u001b[32m0.10602\u001b[0m      1.02932  11.23s\n",
      "      7       \u001b[36m0.10486\u001b[0m       \u001b[32m0.10262\u001b[0m      1.02187  11.22s\n",
      "      8       \u001b[36m0.10172\u001b[0m       \u001b[32m0.10021\u001b[0m      1.01508  11.22s\n",
      "      9       \u001b[36m0.09939\u001b[0m       \u001b[32m0.09742\u001b[0m      1.02020  11.26s\n",
      "     10       \u001b[36m0.09670\u001b[0m       \u001b[32m0.09534\u001b[0m      1.01424  11.22s\n",
      "     11       \u001b[36m0.09482\u001b[0m       \u001b[32m0.09339\u001b[0m      1.01531  11.20s\n",
      "     12       \u001b[36m0.09322\u001b[0m       \u001b[32m0.09219\u001b[0m      1.01114  11.22s\n",
      "     13       \u001b[36m0.09175\u001b[0m       \u001b[32m0.09083\u001b[0m      1.01016  11.23s\n",
      "     14       \u001b[36m0.09037\u001b[0m       \u001b[32m0.08945\u001b[0m      1.01024  11.22s\n",
      "     15       \u001b[36m0.08927\u001b[0m       \u001b[32m0.08828\u001b[0m      1.01118  11.22s\n",
      "     16       \u001b[36m0.08813\u001b[0m       \u001b[32m0.08747\u001b[0m      1.00761  11.22s\n",
      "     17       \u001b[36m0.08735\u001b[0m       \u001b[32m0.08686\u001b[0m      1.00572  11.26s\n",
      "     18       \u001b[36m0.08633\u001b[0m       \u001b[32m0.08592\u001b[0m      1.00481  11.20s\n",
      "     19       \u001b[36m0.08556\u001b[0m       \u001b[32m0.08462\u001b[0m      1.01111  11.22s\n",
      "     20       \u001b[36m0.08482\u001b[0m       \u001b[32m0.08445\u001b[0m      1.00434  11.21s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ae.fit(X_train, X_out)\n",
    "print \n",
    "###  expect training / val error of about 0.087 with these parameters\n",
    "###  if your GPU not fast enough, reduce the number of filters in the conv/deconv step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "pickle.dump(ae, open('mnist/conv_ae.pkl','w'))\n",
    "#ae = pickle.load(open('mnist/conv_ae.pkl','r'))\n",
    "ae.save_params_to('mnist/conv_ae.np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = ae.predict(X_train).reshape(-1, 28, 28) * sigma + mu\n",
    "X_pred = np.rint(X_train_pred).astype(int)\n",
    "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
    "X_pred = X_pred.astype('uint8')\n",
    "print X_pred.shape , X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAABwCAAAAAAiICN+AAAGZUlEQVR4nO3cW6wdVRkH8N/eZ/e0\npUgrYJRYIgkSIUTuKuAFomCfEEqC+AJBMDypD16aaIwaTXzXBzUaTVCboAGhYAANl0AgEI3YRiM0\nRgU1gqBCLdD29PRsH761MmtPZ3ef44MnM51/Mulaa9asPV9X//2uawZWCUMsTRkf4FDqD7AGozS2\nkMaans3zx7X1Oo1ewLZjsNovMI2LJQaYS+0lkxxdIzi3lK5hMWfsKNjBXsC2Y7TaLzBI10jwbH/D\nnCEWU3seB7FexT0mdd9cMd75HewFbDtWjYOl/huY5NkQrxN8PKDSeZmnC9iHdYKPc4KDTTZq53ew\nF7Dt+J9t0ffgram9M13LwTTbs/TjBkLfHUj9zTgbZwpePojn8Gqasz7NX8QrtTU7v4O9gG3HivXg\nJnwXF+EkwadncS3+hWdmPD+otce1+8P0Upl/b8aH8RGcL3TgI3gc9+NJvJau40xyvPcHu4DOC7hi\nPfglfCG1m3TaNbhzxg9muzH7djmWslZwL695Mm7ETald4gXcjXtxezG+Vtim+/Qc7AY6L+CyOfgm\nfB/vxEY8LXhwdupn7MNvcMmM9er8Han8wZHQs1txHU7En/FUuneh0HlL+BO+hVvx9/T8fLq36CjY\nwV7AtmNZHPwYrhe8IPh3Ff6ILbgZH0r3htiLn+Kzwj5twlDoqayrynzDVnwG78B/hO35sPABxzgD\nV+CCYr2f4IvYnfojlX7tNHoB246ZHLwUD6j01k580OHcOh134TSVfrse2xvWHBU/nOOaS0J/nYev\n4LJ0/4f4Jn5Ze+kr8GkRG8r4Kr6mym+scxTsYC9g23HEmMwmfF7FqQXcolm3PS148QiOT2MfdTgH\nByqbM/tuOS5zptC5mX+/w234rcP9zh2Ca9fihjT2Xpyl4uuCo2AHewHbjqkc3CRiHe9L/Z2Cf984\nwmK7hW16G96CU3COybxFGQcdpWtB+HcX4/J07yWh/34ueHtSGj+If6Z17sPLOEbEgs4Q9umTKl+w\n8zvYC9h2TOXghSr+wS5H5l/GTqGbnhA8vE/Ec+pYI7j1itCHF4scxMnYg2/jDhEnHQlOEnpzvSp+\n+oSIw56bfm8zNqQ1en+wC+i8gFM5uK3W/94KFi1t1ROmzMn5A4I3Vwlbksj93YrnVbpyv8l8Yo7F\n7hG26t+EL5r5SZ+j7wY6L2AjB28wmVu4EY+tcOH8N/folHv5PMQY7xe+JBH7/JHIQxC+5QupfYyo\njSHipcem9gahSwlbNcdkelu0C+i8gI0c3KaKgewS9uRKcGLxfJP+HKp04AZh974h9e8V8dWDwict\na7jLIO5Y5EDW4d3CF4R/pD/XiFxH53ewF7DtaOTg21QcukX173o5OAc/Tu1nBIfrKGOcG0VeA/4t\n8vt7U7+sGc16c4Owb/+Sxs/H1Xi9iNU8m8Zz/qPzO9gL2HbMrBfdPWtCDb8QfCD40MTBEmtFrSdh\ncx4q7r2sOjc4n+YdEHFUomb8U0IPwj34fWrnWE7nd7AXsO2YycFtglezcHqae4LQczvwnSlzS5vy\nryKneK7Qce8SsdXHVVyj0ofErlyEjwsdSNTlbMcfinl9rVoX0HkBp9bJPGQyN3GT8Aufr807Fj/A\nlak/FDWcpy7jh3OMc4uobzlP6L57BAd3iZhnjq1sxNuF3rtUVau2XeQyfiW4Wq7d+R3sBWw7pnJw\nC35W9IdCP+2pPTwv6rgJf+w1fFnUmB0J+YwEkRP8hKhte2Ma2y9qbx4V9ulakfO/ROQfiHrV24XP\nmm3QnHfMOrTzO9gL2HZM5eAmfDJdGzWfUyrHvi54N8v/y8h+3iHBmwsEv7aqOJ2xqPp+BfH/wB0i\nN/+Y4D7B07FJG7bzO9gL2HbMrNn+AD6n+bxtHtshzg8tmo1cn13ainPpGoga7GtEbc288BEHeFHE\nTV/Cr8VZ+jJeW559Kt+t8zvYC9h2rMp31eZMxj9zDiGPbRa6bL/wK9eL2psXhf36avHsUHB1oMo5\nljq28zvYC9h2rNq3Dcvzg4Q9uk6VG5yF/OI5F5/PH2bd139XrSvovID/dw422bQZWT+OxDmKvarv\nHh5QfVOtaZ06p7Nu7fwO9gK2HauiB/M3RUvO1FGPATXZr2OTXKy38zqdRi9g27Eq3xet67DyO9o5\nrlKPwdb7Y9X53zoHe1u0S+i8gP8F5aVlUfLkr2gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  show random inputs / outputs side by side\n",
    "\n",
    "def get_picture_array(X, index):\n",
    "    array = X[index].reshape(28,28)\n",
    "    array = np.clip(array, a_min = 0, a_max = 255)\n",
    "    return  array.repeat(4, axis = 0).repeat(4, axis = 1).astype(np.uint8())\n",
    "\n",
    "def get_random_images():\n",
    "    index = np.random.randint(5000)\n",
    "    print index\n",
    "    original_image = Image.fromarray(get_picture_array(X, index))\n",
    "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
    "    new_im = Image.new('L', new_size)\n",
    "    new_im.paste(original_image, (0,0))\n",
    "    rec_image = Image.fromarray(get_picture_array(X_pred, index))\n",
    "    new_im.paste(rec_image, (original_image.size[0],0))\n",
    "    new_im.save('data/test.png', format=\"PNG\")    \n",
    "    \n",
    "get_random_images()\n",
    "IPImage('data/test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(lasagne.layers.input.InputLayer, {'shape': (None, 1, 28, 28)}),\n",
       " (lasagne.layers.conv.Conv2DLayer,\n",
       "  {'filter_size': 7, 'nonlinearity': None, 'num_filters': 32}),\n",
       " (lasagne.layers.pool.MaxPool2DLayer, {'pool_size': 2}),\n",
       " (lasagne.layers.shape.ReshapeLayer, {'shape': ([0], -1)}),\n",
       " (lasagne.layers.dense.DenseLayer, {'num_units': 40}),\n",
       " (lasagne.layers.dense.DenseLayer, {'num_units': 9248}),\n",
       " (lasagne.layers.shape.ReshapeLayer, {'shape': ([0], 32, 17, 17)}),\n",
       " (lasagne.layers.pool.Upscale2DLayer, {'scale_factor': 2}),\n",
       " (lasagne.layers.conv.Conv2DLayer,\n",
       "  {'filter_size': 7, 'nonlinearity': None, 'num_filters': 1}),\n",
       " (lasagne.layers.shape.ReshapeLayer, {'shape': ([0], -1)})]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import get_output\n",
    "## we find the encode layer from our ae, and use it to define an encoding function\n",
    "\n",
    "# encode_layer_index = map(lambda pair : pair[0], ae.layers).index('encode')\n",
    "encode_layer_index = 4\n",
    "encode_layer = ae.get_all_layers()[encode_layer_index]\n",
    "\n",
    "def get_output_from_nn(last_layer, X):\n",
    "    indices = np.arange(128, X.shape[0], 128)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # not splitting into batches can cause a memory error\n",
    "    X_batches = np.split(X, indices)\n",
    "    out = []\n",
    "    for count, X_batch in enumerate(X_batches):\n",
    "        out.append(get_output(last_layer, inputs=X_batch).eval())\n",
    "        sys.stdout.flush()\n",
    "    return np.vstack(out)\n",
    "\n",
    "\n",
    "def encode_input(X):\n",
    "    return get_output_from_nn(encode_layer, X)\n",
    "\n",
    "X_encoded = encode_input(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAEUElEQVR4nO3aS4tcRRQH8F/PdM9k\n1NFEooEwGqMSfCAquhBURIzgQkSy8wuIG3GTlUtx5RfQj+BCXOhKXLkw4AOJIeIDX9kY0WhiZkgy\nMz0zLk4db/V1XHa33PSBS9WtZ/f53/Os6ik0h23/pvmqvog92MQqeuX9cmt8rrNT1t0pT+4zUer+\nhr2ehr+98uR73b6DvbiltJ2u+tvUL31bZW69RvdZOvEN+7V8JI+3NbI016qv4HpcxJnSXuNOYEfI\nZA/DUs65Glg6eQwJ/iZOW0bxWMCVUj6LY2XsIt7DBQywUS3Y0+C4XZUzDMdC/dyxrTdhSWPrnsLL\neBjnqgXex/nqfShwnBc4JoapU7vP0sljWMsMo37NeilX8KLAD/4SmB7BGt4t7Yl/rTtr2t6lbezU\n/Q37NWZt3zTrD+D5Un8HJ/Ec7sOT+Ah/GPVRU2/m9zHzS8dG/9jD2v9v03Ipf8Nb+EbYyGtxN+7C\nx2VMfgf1P0k9OvNLx0J9grep+1Ju9gu/ZU3YxW/xAb4U9vATPI1DZawyN+PDzWqTnbLR0NXA0un4\nNLWeq/3J9DVP4nV8LmzhAKcErveLmHGP8F2HRvFLmunSsVG/9mfmNP7kn1X7KXzRmriJ74SM3iEw\nvyiwTFrUxPq5T/dZOh1dmtQTMrau8WfmBU6ZW9snYsLtavxBzS8fCFuZ67Xzd91n6XR0afogmVOp\n+b5V2hZxg8An+w8IfJdF7uaKkMPV0p+xSdrbmU8zFurvFksMjMbnlwUGa7jUWuB8GTco7xtV384u\n9e6zdDq6dF7weFvjQ2Y8cBhPCB16BWeF3VvCrQLX8xqlvCXkMmWxTd1n6XTzpSkrQ6ETD+MVvFB+\n2TmBX+rU5TJvFdeUuWu4qayR8X6dv+s+S6eD4VarMWOM2/GQwOqskLcFIX81PYhn8IuIPX7HdRp5\nrHVq91k63TwNYdd6InZYLu8/ijzMGdwo8jOHqkUeEXjvx2vCl1kTOGasktR9lk4vT5MY5pnfhsBv\nr9CNK6X9ThFLwK9Clx7EzTgu/Nc38YPAcUGjp+ddDSydzrlFnZ+p6XuRozmKxzQ5APgZH+In3FvG\nHMBLIs54o8xfErZR2aP7LJ2uPZwTspcxxQm8KnKkj+M2oUs/E+dNJ0Qe/Ii4m3FU2M97RB78Qtng\nkuZMqvssnc59GhpdmrmyOl+6T+RFDwgMv8anApuBkLuhwO+Y8FnfxldlnXVNLrz7LJ08hrvdZ+sL\nv2VO+Jl1f+rSLWH78m5N5mQeLWNOG825JnWfpf8PDBOnQalfbo3pG43p63OKpfKsCzmu+2b3acZC\nvfrsqdarO633ngbbjD1qWtScG/YF/pl7ncUWY6V+nj+075Rmvb5zOrQ7LZQyMU//M3HOfzWzh2Oh\nflsO67vZqnr6JG29m3eqalmr8U5c81vpPksnr0vblfqcKMu0fRkb/Nfdm7St7bvj9XfRfZZOfMO/\nAUFNIN0F3lwIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
    "final_layer = ae.get_all_layers()[-1]\n",
    "new_layer = InputLayer(shape=(None, encode_layer.num_units))\n",
    "\n",
    "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
    "next_layer.input_layer = new_layer\n",
    "\n",
    "def decode_encoded_input(X):\n",
    "    return get_output_from_nn(final_layer, X)\n",
    "\n",
    "X_decoded = decode_encoded_input(X_encoded) * sigma + mu\n",
    "\n",
    "X_decoded = np.rint(X_decoded ).astype(int)\n",
    "X_decoded = np.clip(X_decoded, a_min = 0, a_max = 255)\n",
    "X_decoded  = X_decoded.astype('uint8')\n",
    "print X_decoded.shape\n",
    "\n",
    "### check it worked :\n",
    "\n",
    "pic_array = get_picture_array(X_decoded, np.random.randint(len(X_decoded)))\n",
    "image = Image.fromarray(pic_array)\n",
    "image.save('data/test.png', format=\"PNG\")  \n",
    "IPImage('data/test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
