{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# add to kfkd.py\n",
      "from lasagne import layers\n",
      "from lasagne.updates import nesterov_momentum\n",
      "from nolearn.lasagne import NeuralNet\n",
      "import numpy as np\n",
      "import theano.tensor as T\n",
      "from nolearn.lasagne import BatchIterator\n",
      "from theano.sandbox.neighbours import neibs2images\n",
      "from lasagne.objectives import mse\n",
      "\n",
      "### this is really dumb, current nolearn doesnt play well with lasagne, \n",
      "### so had to manually copy the file I wanted to this folder\n",
      "from shape import ReshapeLayer\n",
      "\n",
      "from lasagne.nonlinearities import tanh\n",
      "import pickle\n",
      "import sys\n",
      "from sklearn.metrics import mean_squared_error as mse\n",
      "from sklearn.metrics import precision_score\n",
      "import os\n",
      "import urllib\n",
      "import gzip\n",
      "import cPickle\n",
      "from IPython.display import Image as IPImage\n",
      "from PIL import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Unpool2DLayer(layers.Layer):\n",
      "    \"\"\"\n",
      "    This layer performs unpooling over the last two dimensions\n",
      "    of a 4D tensor.\n",
      "    \"\"\"\n",
      "    def __init__(self, incoming, ds, **kwargs):\n",
      "        \n",
      "        super(Unpool2DLayer, self).__init__(incoming, **kwargs)\n",
      "\n",
      "        if (isinstance(ds, int)):\n",
      "            raise ValueError('ds must have len == 2')\n",
      "        else:\n",
      "            ds = tuple(ds)\n",
      "            if len(ds) != 2:\n",
      "                raise ValueError('ds must have len == 2')\n",
      "            if ds[0] != ds[1]:\n",
      "                raise ValueError('ds should be symmetric (I am lazy)')\n",
      "            self.ds = ds\n",
      "\n",
      "    def get_output_shape_for(self, input_shape):\n",
      "        output_shape = list(input_shape)\n",
      "\n",
      "        output_shape[2] = input_shape[2] * self.ds[0]\n",
      "        output_shape[3] = input_shape[3] * self.ds[1]\n",
      "\n",
      "        return tuple(output_shape)\n",
      "\n",
      "    def get_output_for(self, input, **kwargs):\n",
      "        ds = self.ds\n",
      "        input_shape = input.shape\n",
      "        output_shape = self.get_output_shape_for(input_shape)\n",
      "        return input.repeat(2, axis = 2).repeat(2, axis = 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### when we load the batches to input to the neural network, we randomly / flip rotate the images, to artificially\n",
      "### increase the size of the training set\n",
      "\n",
      "class FlipBatchIterator(BatchIterator):\n",
      "\n",
      "    def transform(self, X1, X2):\n",
      "        X1b, X2b = super(FlipBatchIterator, self).transform(X1, X2)\n",
      "        X2b = X2b.reshape(X1b.shape)\n",
      "\n",
      "        bs = X1b.shape[0]\n",
      "        h_indices = np.random.choice(bs, bs / 2, replace=False) # horizontal flip\n",
      "        v_indices = np.random.choice(bs, bs / 2, replace=False) # vertical flip\n",
      "        \n",
      "        ###  uncomment these lines if you want to include rotations (images must be square)  ###\n",
      "        #r_indices = np.random.choice(bs, bs / 2, replace=False) # 90 degree rotation\n",
      "        for X in (X1b, X2b):\n",
      "            X[h_indices] = X[h_indices, :, :, ::-1]\n",
      "            X[v_indices] = X[v_indices, :, ::-1, :]\n",
      "            #X[r_indices] = np.swapaxes(X[r_indices, :, :, :], 2, 3)\n",
      "        shape = X2b.shape\n",
      "        X2b = X2b.reshape((shape[0], -1))\n",
      "\n",
      "        return X1b, X2b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = 'mnist/mnist.pkl.gz'\n",
      "if not os.path.isfile(fname):\n",
      "    testfile = urllib.URLopener()\n",
      "    testfile.retrieve(\"http://deeplearning.net/data/mnist/mnist.pkl.gz\", fname)\n",
      "f = gzip.open(fname, 'rb')\n",
      "train_set, valid_set, test_set = cPickle.load(f)\n",
      "f.close()\n",
      "X, y = train_set\n",
      "X = np.rint(X * 256).astype(np.int).reshape((-1, 1, 28,28)) # convert to (0,255) int range (we'll do our own scaling)\n",
      "mu, sigma = np.mean(X.flatten()), np.std(X.flatten())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = X.astype(np.float64)\n",
      "X_train = (X_train - mu) / sigma\n",
      "X_train = X_train.astype(np.float32)\n",
      "\n",
      "# we need our target to be 1 dimensional\n",
      "X_out = X_train.reshape((X_train.shape[0], -1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conv_filters = 32\n",
      "deconv_filters = 32\n",
      "filter_sizes = 7\n",
      "epochs = 20\n",
      "encode_size = 40\n",
      "ae = NeuralNet(\n",
      "    layers=[\n",
      "        ('input', layers.InputLayer),\n",
      "        ('conv', layers.Conv2DLayer),\n",
      "        ('pool', layers.MaxPool2DLayer),\n",
      "        ('flatten', ReshapeLayer), # output_dense\n",
      "        ('encode_layer', layers.DenseLayer),\n",
      "        ('hidden', layers.DenseLayer), # output_dense\n",
      "        ('unflatten', ReshapeLayer),\n",
      "        ('unpool', Unpool2DLayer),\n",
      "        ('deconv', layers.Conv2DLayer),\n",
      "        ('output_layer', ReshapeLayer),\n",
      "        ],\n",
      "    input_shape=(None, 1, 28, 28),\n",
      "    conv_num_filters=conv_filters, conv_filter_size = (filter_sizes, filter_sizes), \n",
      "    conv_border_mode=\"valid\",\n",
      "    conv_nonlinearity=None,\n",
      "    pool_ds=(2, 2),\n",
      "    flatten_shape=(([0], -1)), # not sure if necessary?\n",
      "    encode_layer_num_units = encode_size,\n",
      "    hidden_num_units= deconv_filters * (28 + filter_sizes - 1) ** 2 / 4,\n",
      "    unflatten_shape=(([0], deconv_filters, (28 + filter_sizes - 1) / 2, (28 + filter_sizes - 1) / 2 )),\n",
      "    unpool_ds=(2, 2),\n",
      "    deconv_num_filters=1, deconv_filter_size = (filter_sizes, filter_sizes), \n",
      "    deconv_border_mode=\"valid\",\n",
      "    deconv_nonlinearity=None,\n",
      "    output_layer_shape = (([0], -1)),\n",
      "    update_learning_rate = 0.01,\n",
      "    update_momentum = 0.975,\n",
      "    batch_iterator_train=FlipBatchIterator(batch_size=128),\n",
      "    regression=True,\n",
      "    max_epochs= epochs,\n",
      "    verbose=1,\n",
      "    )\n",
      "ae.fit(X_train, X_out)\n",
      "print \n",
      "###  expect training / val error of about 0.087 with these parameters\n",
      "###  if your GPU not fast enough, reduce the number of filters in the conv/deconv step"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  input             \t(None, 1, 28, 28)   \tproduces     784 outputs\n",
        "  conv              \t(None, 32, 22, 22)  \tproduces   15488 outputs\n",
        "  pool              \t(None, 32, 11, 11)  \tproduces    3872 outputs\n",
        "  flatten           \t(None, 3872)        \tproduces    3872 outputs\n",
        "  encode_layer      \t(None, 40)          \tproduces      40 outputs\n",
        "  hidden            \t(None, 9248)        \tproduces    9248 outputs\n",
        "  unflatten         \t(None, 32, 17, 17)  \tproduces    9248 outputs\n",
        "  unpool            \t(None, 32, 34, 34)  \tproduces   36992 outputs\n",
        "  deconv            \t(None, 1, 28, 28)   \tproduces     784 outputs\n",
        "  output_layer      \t(None, 784)         \tproduces     784 outputs\n",
        "\n",
        " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
        "--------|--------------|--------------|---------------|-------------|-------"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     1  |  \u001b[94m  0.431822\u001b[0m  |  \u001b[32m  0.213204\u001b[0m  |     2.025398  |             |  17.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     2  |  \u001b[94m  0.173916\u001b[0m  |  \u001b[32m  0.148604\u001b[0m  |     1.170338  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     3  |  \u001b[94m  0.137808\u001b[0m  |  \u001b[32m  0.128491\u001b[0m  |     1.072508  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     4  |  \u001b[94m  0.123215\u001b[0m  |  \u001b[32m  0.117774\u001b[0m  |     1.046200  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     5  |  \u001b[94m  0.114462\u001b[0m  |  \u001b[32m  0.110565\u001b[0m  |     1.035243  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     6  |  \u001b[94m  0.108447\u001b[0m  |  \u001b[32m  0.105524\u001b[0m  |     1.027706  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     7  |  \u001b[94m  0.103732\u001b[0m  |  \u001b[32m  0.101377\u001b[0m  |     1.023228  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     8  |  \u001b[94m  0.100801\u001b[0m  |  \u001b[32m  0.099143\u001b[0m  |     1.016725  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "     9  |  \u001b[94m  0.098258\u001b[0m  |  \u001b[32m  0.096690\u001b[0m  |     1.016225  |             |  17.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    10  |  \u001b[94m  0.096188\u001b[0m  |  \u001b[32m  0.095318\u001b[0m  |     1.009123  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    11  |  \u001b[94m  0.094448\u001b[0m  |  \u001b[32m  0.093405\u001b[0m  |     1.011170  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    12  |  \u001b[94m  0.093127\u001b[0m  |  \u001b[32m  0.092129\u001b[0m  |     1.010840  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    13  |  \u001b[94m  0.091796\u001b[0m  |  \u001b[32m  0.090586\u001b[0m  |     1.013360  |             |  17.5s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    14  |  \u001b[94m  0.090857\u001b[0m  |  \u001b[32m  0.090093\u001b[0m  |     1.008483  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    15  |  \u001b[94m  0.089476\u001b[0m  |  \u001b[32m  0.088852\u001b[0m  |     1.007025  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    16  |  \u001b[94m  0.088696\u001b[0m  |  \u001b[32m  0.087847\u001b[0m  |     1.009674  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    17  |  \u001b[94m  0.088271\u001b[0m  |  \u001b[32m  0.087701\u001b[0m  |     1.006506  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    18  |  \u001b[94m  0.086999\u001b[0m  |  \u001b[32m  0.086294\u001b[0m  |     1.008174  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    19  |  \u001b[94m  0.086128\u001b[0m  |  \u001b[32m  0.085750\u001b[0m  |     1.004407  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "    20  |  \u001b[94m  0.085365\u001b[0m  |  \u001b[32m  0.084888\u001b[0m  |     1.005624  |             |  17.4s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 75,
       "text": [
        "NeuralNet(X_tensor_type=<function tensor4 at 0x7fb26b597d70>,\n",
        "     batch_iterator_test=<nolearn.lasagne.base.BatchIterator object at 0x7fb243586410>,\n",
        "     batch_iterator_train=<__main__.FlipBatchIterator object at 0x7fb272221110>,\n",
        "     conv_border_mode='valid', conv_filter_size=(7, 7),\n",
        "     conv_nonlinearity=None, conv_num_filters=32,\n",
        "     deconv_border_mode='valid', deconv_filter_size=(7, 7),\n",
        "     deconv_nonlinearity=None, deconv_num_filters=1,\n",
        "     encode_layer_num_units=40, eval_size=0.2, flatten_shape=([0], -1),\n",
        "     hidden_num_units=9248, input_shape=(None, 1, 28, 28),\n",
        "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('conv', <class 'lasagne.layers.conv.Conv2DLayer'>), ('pool', <class 'lasagne.layers.pool.MaxPool2DLayer'>), ('flatten', <class 'shape.ReshapeLayer'>), ('encode_layer', <class 'lasagne.layers.dense.DenseLayer'>), ('hidden', <class 'lasagn...deconv', <class 'lasagne.layers.conv.Conv2DLayer'>), ('output_layer', <class 'shape.ReshapeLayer'>)],\n",
        "     loss=None, max_epochs=20, more_params={},\n",
        "     objective=<class 'lasagne.objectives.Objective'>,\n",
        "     objective_loss_function=<function mse at 0x7fb244764398>,\n",
        "     on_epoch_finished=(), on_training_finished=(),\n",
        "     output_layer_shape=([0], -1), pool_ds=(2, 2), regression=True,\n",
        "     unflatten_shape=([0], 32, 17, 17), unpool_ds=(2, 2),\n",
        "     update=<function nesterov_momentum at 0x7fb2447648c0>,\n",
        "     update_learning_rate=0.01, update_momentum=0.975,\n",
        "     use_label_encoder=False, verbose=1,\n",
        "     y_tensor_type=TensorType(float32, matrix))"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "import sys\n",
      "sys.setrecursionlimit(10000)\n",
      "\n",
      "pickle.dump(ae, open('mnist/conv_ae.pkl','w'))\n",
      "#ae = pickle.load(open('mnist/conv_ae.pkl','r'))\n",
      "ae.save_weights_to('mnist/conv_ae.np')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_pred = ae.predict(X_train).reshape(-1, 28, 28) * sigma + mu\n",
      "X_pred = np.rint(X_train_pred).astype(int)\n",
      "X_pred = np.clip(X_pred, a_min = 0, a_max = 255)\n",
      "X_pred = X_pred.astype('uint8')\n",
      "print X_pred.shape , X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 28, 28) (50000, 1, 28, 28)\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###  show random inputs / outputs side by side\n",
      "\n",
      "def get_picture_array(X, index):\n",
      "    array = X[index].reshape(28,28)\n",
      "    array = np.clip(array, a_min = 0, a_max = 255)\n",
      "    return  array.repeat(4, axis = 0).repeat(4, axis = 1).astype(np.uint8())\n",
      "\n",
      "def get_random_images():\n",
      "    index = np.random.randint(5000)\n",
      "    print index\n",
      "    original_image = Image.fromarray(get_picture_array(X, index))\n",
      "    new_size = (original_image.size[0] * 2, original_image.size[1])\n",
      "    new_im = Image.new('L', new_size)\n",
      "    new_im.paste(original_image, (0,0))\n",
      "    rec_image = Image.fromarray(get_picture_array(X_pred, index))\n",
      "    new_im.paste(rec_image, (original_image.size[0],0))\n",
      "    new_im.save('data/test.png', format=\"PNG\")    \n",
      "    \n",
      "get_random_images()\n",
      "IPImage('data/test.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1273\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAABwCAAAAAAiICN+AAAGGUlEQVR4nO3cX6hlVR0H8M+Zc/85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\n+BeyWlZwVlQRCgAAAABJRU5ErkJggg==\n",
       "prompt_number": 94,
       "text": [
        "<IPython.core.display.Image at 0x7fb26228aa90>"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## we find the encode layer from our ae, and use it to define an encoding function\n",
      "\n",
      "encode_layer_index = map(lambda pair : pair[0], ae.layers).index('encode_layer')\n",
      "encode_layer = ae.get_all_layers()[encode_layer_index]\n",
      "\n",
      "def get_output_from_nn(last_layer, X):\n",
      "    indices = np.arange(128, X.shape[0], 128)\n",
      "    sys.stdout.flush()\n",
      "    \n",
      "    # not splitting into batches can cause a memory error\n",
      "    X_batches = np.split(X, indices)\n",
      "    out = []\n",
      "    for count, X_batch in enumerate(X_batches):\n",
      "        out.append(last_layer.get_output(X_batch).eval())\n",
      "        sys.stdout.flush()\n",
      "    return np.vstack(out)\n",
      "\n",
      "\n",
      "def encode_input(X):\n",
      "    return get_output_from_nn(encode_layer, X)\n",
      "\n",
      "X_encoded = encode_input(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_layer = ae.get_all_layers()[encode_layer_index + 1]\n",
      "final_layer = ae.get_all_layers()[-1]\n",
      "new_layer = layers.InputLayer(shape = (None, encode_layer.num_units))\n",
      "\n",
      "# N.B after we do this, we won't be able to use the original autoencoder , as the layers are broken up\n",
      "next_layer.input_layer = new_layer\n",
      "\n",
      "def decode_encoded_input(X):\n",
      "    return get_output_from_nn(final_layer, X)\n",
      "\n",
      "X_decoded = decode_encoded_input(X_encoded) * sigma + mu\n",
      "\n",
      "X_decoded = np.rint(X_decoded ).astype(int)\n",
      "X_decoded = np.clip(X_decoded, a_min = 0, a_max = 255)\n",
      "X_decoded  = X_decoded.astype('uint8')\n",
      "print X_decoded.shape\n",
      "\n",
      "### check it worked :\n",
      "\n",
      "pic_array = get_picture_array(X_decoded, np.random.randint(len(X_decoded)))\n",
      "image = Image.fromarray(pic_array)\n",
      "image.save('data/test.png', format=\"PNG\")  \n",
      "IPImage('data/test.png')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(50000, 784)\n"
       ]
      }
     ],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}